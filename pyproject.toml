[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "bft-federated"
version = "1.0.0"
description = "Federated Learning with Byzantine Fault Tolerance (BFT)"
license = "Apache-2.0"
dependencies = [
    "flwr[simulation]>=1.12.0",
    "flwr-datasets[vision]>=0.3.0",
    "torch==2.2.1",
    "torchvision==0.17.1",
    "wandb==0.18.7",
]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "muticia"

[tool.flwr.app.components]
serverapp = "app.server_app:app"
clientapp = "app.client_app:app"

[tool.flwr.federations]
default = "local-simulation"

[tool.flwr.app.config]
num-server-rounds = 5           # For better model convergence consider more server rounds
fraction-fit = 1               # Ensure at least f+1 clients participate in each round for BFT
local-epochs = 2                # Epochs for local model training

# BFT Configuration 
byzantine_threshold = 0.7                 # Higher threshold for stronger aggregation consensus
max_deviation_threshold = "krum"             # BFT method to handle Byzantine clients during aggregation. Options: "krum", "trimmed_mean", "median"
byzantine-clients = 5           # Number of malicious clients to simulate (ensure N > 3f is still satisfied)
min-clients = 16                # Minimum number of clients for BFT simulation
[tool.flwr.federations.local-simulation]
options.num-supernodes = 100     # Sufficient supernodes to handle aggregation in BFT scenarios
options.num-nodes = 100          # Total number of nodes must satisfy N > 3f for BFT (with f = 5 Byzantine clients, N = 16+)
options.num-clients = 100        # Ensure enough clients for a robust BFT simulation, satisfying N > 3f
options.num-epochs = 10         # Number of epochs for local training
options.batch-size = 32         # Batch size for training
options.lr = 0.01               # Learning rate for local updates
options.seed = 42               # Seed for reproducibility

